# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mmhjZ6dS69L9zK99P8OJKXaEfWZtskTm
"""



import torch
from torch import nn
from torchvision import datasets
from torchvision import transforms
from torch.utils.data import DataLoader
from torch.nn.utils import clip_grad_norm_
import os

import os
os.cpu_count()

device = torch.device("cuda" if torch.cuda.is_available()else "cpu")
device

from torch import nn

class PatchEmbedding(nn.Module):
    """
    Reduces a 32x32 image with three stride-2 AvgPool2d ops:
    32 -> 16 -> 8 -> 4, then projects to embedding_dim.
    num_patches = (img_size//8) * (img_size//8).
    """
    def __init__(self,
                 in_channels: int = 3,

                 embedding_dim: int = 192,
                 img_size: int = 32):
        super().__init__()
        assert img_size % 8 == 0, \
            f"img_size {img_size} must be divisible by 8 due to three stride-2 pools."


        self.patcher = nn.Sequential(

    # Block 1: 32x32 -> 16x16
    nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),
    nn.BatchNorm2d(64),
    nn.GELU(),
    nn.Conv2d(64, 64, kernel_size=3, padding=1),
    nn.BatchNorm2d(64),
    nn.GELU(),
    nn.AvgPool2d(kernel_size=2, stride=2),

    # Block 2: 16x16 -> 8x8
    nn.Conv2d(64, 128, kernel_size=3, padding=1),
    nn.BatchNorm2d(128),
    nn.GELU(),
    nn.Conv2d(128, 128, kernel_size=3, padding=1),
    nn.BatchNorm2d(128),
    nn.GELU(),
    nn.AvgPool2d(kernel_size=2, stride=2),

    # Block 3: 8x8 -> 4x4
    nn.Conv2d(128, 256, kernel_size=3, padding=1),
    nn.BatchNorm2d(256),
    nn.GELU(),
    nn.Conv2d(256, 256, kernel_size=3, padding=1),
    nn.BatchNorm2d(256),
    nn.GELU(),
    nn.AvgPool2d(kernel_size=2, stride=2),

    # Project to embedding_dim, keep HxW (now 4x4 for img_size=32)
    nn.Conv2d(256, embedding_dim, kernel_size=1),
    nn.BatchNorm2d(embedding_dim),
    nn.GELU()
)


        self.grid_h = img_size // 8
        self.grid_w = img_size // 8
        self.num_patches = self.grid_h * self.grid_w
        self.flatten = nn.Flatten(start_dim=2, end_dim=3)

    def forward(self, x):
        x = self.patcher(x)
        x = self.flatten(x)
        x = x.permute(0, 2, 1)
        return x






class MultiHeadSelfAttentionBlock(nn.Module):
  def __init__(self,embedding_dim:int=192,num_heads:int=2,attention_dropout:float=0.0):
    super().__init__()

    self.layer_norm = nn.LayerNorm(normalized_shape=embedding_dim)
    self.MSA = nn.MultiheadAttention(embed_dim=embedding_dim,num_heads=num_heads,dropout=attention_dropout, batch_first=True)

  def forward(self,x):
    x= self.layer_norm(x)
    att_output, _ = self.MSA(query=x,
                             key=x,
                             value=x.contiguous(),
                             need_weights=False)

    return att_output


class MLPBlock(nn.Module):
  def __init__(self,embedding_dim:int=192,mlp_size:int=1152,dropout:float=0.1):

    super().__init__()

    self.layer_norm = nn.LayerNorm(normalized_shape= embedding_dim)
    self.mlp = nn.Sequential(
    # First hidden layer
    nn.Linear(in_features=embedding_dim,
              out_features=mlp_size),
   nn.GELU(),
    nn.Dropout(p=dropout),



    # Output layer
    nn.Linear(in_features=mlp_size,
              out_features=embedding_dim),
    nn.Dropout(p=dropout)
)



  def forward(self,x):
    x = self.layer_norm(x)
    x= self.mlp(x)

    return x



class TransformerEncoderBlock(nn.Module):
  def __init__(self, embedding_dim:int=192, num_heads:int=2,mlp_size:int=1152, mlp_dropout:float=0.1, att_dropout:float=0.0):
    super().__init__()

    self.MSAblock = MultiHeadSelfAttentionBlock(embedding_dim = embedding_dim,num_heads=num_heads, attention_dropout = att_dropout)
    self.MLPblock= MLPBlock(embedding_dim=embedding_dim , mlp_size = mlp_size, dropout = mlp_dropout)

  def forward(self,x):
    x= x + self.MSAblock(x)
    x= x+ self.MLPblock(x)

    return x

class VIT(nn.Module):
  def __init__(self,in_channels:int=3,embedding_dim:int=192,num_heads:int=2,num_transformer_layers:int=2,attention_dropout:float=0.0,mlp_size:int=1152,mlp_dropout:float=0.1,embedding_dropout:float=0.1,num_classes:int=10, img_size:int=32):
    super().__init__()

    assert embedding_dim % num_heads == 0, \
            f"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads})."

        # Patch embedding via CNN pyramid
    self.patch_embedding = PatchEmbedding(in_channels=in_channels,
                                              embedding_dim=embedding_dim,img_size=img_size)

        # 4. Calculate number of patches (height * width/patch^2)
    self.num_patches = self.patch_embedding.num_patches

        # 5. Create learnable class embedding
    self.class_embedding = nn.Parameter(data=torch.randn(1, 1, embedding_dim),
                                            requires_grad=True)

        # 6. Create learnable position embedding
    self.position_embedding = nn.Parameter(data=torch.randn(1, self.num_patches+1, embedding_dim),
                                               requires_grad=True)

        # 7. Create embedding dropout value
    self.embedding_dropout = nn.Dropout(p=embedding_dropout)



    self.transformer_encoder = nn.Sequential(*[TransformerEncoderBlock(embedding_dim=embedding_dim, num_heads=num_heads,mlp_size=mlp_size, mlp_dropout=mlp_dropout, att_dropout=attention_dropout) for _ in range(num_transformer_layers)])
    self.classifier = nn.Sequential(nn.LayerNorm(normalized_shape=embedding_dim), nn.Linear(in_features=embedding_dim,out_features=num_classes))

  def forward(self,x):
   batch_size = x.shape[0]
   class_token = self.class_embedding.expand(batch_size,-1,-1)
   x = self.patch_embedding(x)
   x= torch.cat((class_token,x),dim=1)
   x= self.position_embedding.to(x.device) + x
   x= self.embedding_dropout(x)
   x= self.transformer_encoder(x)
   x= self.classifier(x[:,0])

   return x

num_params = sum(p.numel() for p in model.parameters())
num_params

import math

def lr_scheduler(step, total_steps=78125, warmup_steps=21000):
    if step < warmup_steps:
        return  (step + 1) / warmup_steps
    progress = (step - warmup_steps) / (total_steps - warmup_steps)
    return 0.5 * (1 + math.cos(math.pi * progress))  # cosine decay

loss_fn= nn.CrossEntropyLoss()
optim = torch.optim.AdamW(
    model.parameters(),
    lr= 1e-3,
    weight_decay=0.001,
    betas=(0.9, 0.999),
    eps=1e-8
)
scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lr_scheduler)

import torch
import torch.nn.functional as F

def mixup_data(x, y, alpha=0.2, device='cuda'):
    """Returns mixed inputs, pairs of targets, and lambda"""
    if alpha > 0:
        lam = torch.distributions.Beta(alpha, alpha).sample().to(device)
    else:
        lam = 0.5

    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(device)

    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam

def mixup_criterion(loss_fn, pred, y_a, y_b, lam):
    return lam * loss_fn(pred, y_a) + (1 - lam) * loss_fn(pred, y_b)

import numpy as np
seed= 42

torch.manual_seed(seed) # for cpu operations
torch.cuda.manual_seed(seed) # for GPU opearations
np.random.seed(seed) # for numpy operations



def train(dataloader, model, loss_fn, optim, scheduler, device):
    model.train()
    total_samples = len(dataloader.dataset)
    num_batches = len(dataloader)
    train_loss=0

    for batch_idx, (x, y) in enumerate(dataloader):
        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)
        x, y_a, y_b, lam = mixup_data(x, y, alpha=0.2, device=device)

        optim.zero_grad()
        preds = model(x)
        loss =  mixup_criterion(loss_fn, preds, y_a, y_b, lam)
        train_loss+=loss.item()
        loss.backward()
        clip_grad_norm_(model.parameters(), max_norm=1.0)
        optim.step()
        scheduler.step()

        if batch_idx % 100 == 0:
            num_samples_processed = (batch_idx + 1) * len(x)
            print(f"loss: {loss.item():.4f} | samples_processed: {num_samples_processed} / {total_samples}")

    train_loss/=num_batches
    return train_loss

def test(dataloader, model, loss_fn, device):
    model.eval()
    num_samples = len(dataloader.dataset)
    num_batches = len(dataloader)
    test_loss, correct_preds = 0, 0

    with torch.inference_mode():
        for x, y in dataloader:
            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)
            preds = model(x)
            test_loss += loss_fn(preds, y).item()
            probs = torch.softmax(preds, dim=1)
            correct_preds += (probs.argmax(dim=1) == y).sum().item()

    test_loss /= num_batches
    acc = (correct_preds / num_samples) * 100
    print(f"average_test_loss: {test_loss:.4f}  |  accuracy: {acc:.2f}%")

    return test_loss, acc

epochs=50
train_losses=[]
val_losses=[]
val_accuracies=[]

for epoch in range(epochs):
  print(f"epoch:{epoch+1}\n---------------------")



  train_loss=train(train_dataloader,model,loss_fn,optim,scheduler, device)
  train_losses.append(train_loss)

  test_loss, acc= test(test_dataloader, model, loss_fn,device)
  val_losses.append(test_loss)
  val_accuracies.append(acc)


print("Training Done!")

import matplotlib.pyplot as plt

train_loss = train_losses
test_loss = val_losses


plt.plot(range(epochs), train_loss, label  ="train loss", color = "green", marker="x", markersize=3)
plt.plot(range(epochs), test_loss, label  = "test loss",  color = "blue", marker = "x", markersize=3)
plt.xlabel("epochs")
plt.ylabel("loss")
plt.title("train loss vs test loss")
plt.legend()
plt.show()



test_acc = val_accuracies

plt.figure(figsize=(8,5))
plt.plot(range(epochs), test_acc, label="test accuracy", color="red", marker="x", markersize=3)
plt.xlabel("epcohs")
plt.ylabel("accuracy")
plt.title("test accuracy")
plt.legend()
plt.show()

fig=plt.figure(figsize=(19,7))
model.eval()
classes = train_data.classes

rows,cols= 5,5

with torch.inference_mode():
  for i in range(1,rows*cols+1):
    random_idx = torch.randint(0,len(test_data), size=[1]).item()
    x,y= test_data[random_idx]

    x= x.unsqueeze(dim=0).to(device)
    preds = model(x)
    predicted_class = preds.argmax(dim=1).item()

    fig.add_subplot(rows,cols,i)
    plt.imshow(x.squeeze().permute(1,2,0).cpu())
    title_text = f"Predicted class:{classes[predicted_class]}  |  True label:{classes[y]}"

    if predicted_class==y:
      plt.title(title_text, fontsize=10,c="g")
    else:
      plt.title(title_text, fontsize=10, c="r")

    plt.axis(False)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def plot_confusion_matrix(model, dataloader,classes, device):

    model.eval()
    y_true, y_pred = [], []

    with torch.inference_mode():
        for x, y in dataloader:
            x, y = x.to(device), y.to(device)
            preds = model(x)
            predicted_classes = preds.argmax(dim=1)
            y_true.extend(y.cpu().numpy())
            y_pred.extend(predicted_classes.cpu().numpy())

    cm = confusion_matrix(y_true, y_pred)

    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=classes, yticklabels=classes)
    plt.xlabel('Predicted label')
    plt.ylabel('True label')
    plt.title('Confusion Matrix')
    plt.show()

import argparse
parser = argparse.ArgmentParser()
parser.add_argument

def main():
    parser = argparse.ArgumentParser(description="Train Vision Transformer on CIFAR-10")
    parser.add_argument("--epochs", type=int, default=10)
    parser.add_argument("--batch-size", type=int, default=32)
    parser.add_argument("--lr", type=float, default=3e-4)
    parser.add_argument("--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu")
    args = parser.parse_args()

    # ---- SETUP ----
    np.random.seed(42)
    torch.manual_seed(42)
    torch.cuda.manual_seed(42)

    device = torch.device(args.device)

    # ---- DATA ----
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.TrivialAugmentWide(),
        transforms.ToTensor(),
        transforms.Normalize([0.4914, 0.4822, 0.4465],
                             [0.2470, 0.2435, 0.2616])
    ])
    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.4914, 0.4822, 0.4465],
                             [0.2470, 0.2435, 0.2616])
    ])

    train_data = datasets.CIFAR10(root="dataset", train=True, download=True, transform=transform_train)
    test_data = datasets.CIFAR10(root="dataset", train=False, download=True, transform=transform_test)

    train_dataloader = DataLoader(train_data, batch_size=args.batch_size,
                                  shuffle=True, pin_memory=True, num_workers=os.cpu_count())
    test_dataloader = DataLoader(test_data, batch_size=args.batch_size,
                                 shuffle=False, pin_memory=True, num_workers=os.cpu_count())

    # ---- MODEL ----
    model = VIT().to(device)
    loss_fn = nn.CrossEntropyLoss()

    optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=1e-3,
    weight_decay=0.001,
    betas=(0.9, 0.999),
    eps=1e-8
)

# Custom learning rate scheduler
    def lr_lambda(step, total_steps=len(train_dataloader)*args.epochs, warmup_steps=21000):
      if step < warmup_steps:
        return (step + 1) / warmup_steps
      progress = (step - warmup_steps) / (total_steps - warmup_steps)
      return 0.5 * (1 + math.cos(math.pi * progress))

    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)

    # ---- TRAINING LOOP ----
    for epoch in range(args.epochs):
        print(f"\nEpoch {epoch+1}/{args.epochs}")
        train_loss = train(train_dataloader, model, loss_fn, optimizer, scheduler, device=device)
        print(f"Train Loss: {train_loss:.4f}")
        test(test_dataloader, model, loss_fn, device)

    #---- Confusion Matrix----

    classes = train_data.classes  # CIFAR-10 class names
    plot_confusion_matrix(model, test_dataloader, classes, device)



if __name__ == "__main__":
    main()